{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "7a4a6980-8513-495d-8068-323f5268f844",
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "from os import listdir\n",
    "from os.path import isfile, join\n",
    "import numpy as np\n",
    "from math import floor\n",
    "from scipy.ndimage import zoom, rotate\n",
    "import imageio\n",
    "import face_recognition\n",
    "from tensorflow.keras.models import Model as KerasModel\n",
    "from tensorflow.keras.layers import Input, Dense, Flatten, Conv2D, MaxPooling2D, BatchNormalization, Dropout, Reshape, Concatenate, LeakyReLU\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "IMGWIDTH = 256"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "19911705-3ed9-4def-adb7-3f7a3c97020d",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Classifier:\n",
    "    def __init__():\n",
    "        self.model = 0\n",
    "    \n",
    "    def predict(self, x):\n",
    "        if x.size == 0:\n",
    "            return []\n",
    "        return self.model.predict(x)\n",
    "    \n",
    "    def fit(self, x, y):\n",
    "        return self.model.train_on_batch(x, y)\n",
    "    \n",
    "    def get_accuracy(self, x, y):\n",
    "        return self.model.test_on_batch(x, y)\n",
    "    \n",
    "    def load(self, path):\n",
    "        self.model.load_weights(path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "02646f68-ffd2-4b8f-a51f-c62fe983581f",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Meso1(Classifier):\n",
    "   \n",
    "    def __init__(self, learning_rate = 0.001, dl_rate = 1):\n",
    "        self.model = self.init_model(dl_rate)\n",
    "        optimizer = Adam(learning_rate = learning_rate)\n",
    "        self.model.compile(optimizer = optimizer, loss = 'mean_squared_error', metrics = ['accuracy'])\n",
    "    \n",
    "    def init_model(self, dl_rate):\n",
    "        x = Input(shape = (IMGWIDTH, IMGWIDTH, 3))\n",
    "        \n",
    "        x1 = Conv2D(16, (3, 3), dilation_rate = dl_rate, strides = 1, padding='same', activation = 'relu')(x)\n",
    "        x1 = Conv2D(4, (1, 1), padding='same', activation = 'relu')(x1)\n",
    "        x1 = BatchNormalization()(x1)\n",
    "        x1 = MaxPooling2D(pool_size=(8, 8), padding='same')(x1)\n",
    "\n",
    "        y = Flatten()(x1)\n",
    "        y = Dropout(0.5)(y)\n",
    "        y = Dense(1, activation = 'sigmoid')(y)\n",
    "        return KerasModel(inputs = x, outputs = y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "5e330c25-ed83-40d8-bc44-10393df28e56",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Meso4(Classifier):\n",
    "    def __init__(self, learning_rate = 0.001):\n",
    "        self.model = self.init_model()\n",
    "        optimizer = Adam(learning_rate = learning_rate)\n",
    "        self.model.compile(optimizer = optimizer, loss = 'mean_squared_error', metrics = ['accuracy'])\n",
    "    \n",
    "    def init_model(self): \n",
    "        x = Input(shape = (IMGWIDTH, IMGWIDTH, 3))\n",
    "        \n",
    "        x1 = Conv2D(8, (3, 3), padding='same', activation = 'relu')(x)\n",
    "        x1 = BatchNormalization()(x1)\n",
    "        x1 = MaxPooling2D(pool_size=(2, 2), padding='same')(x1)\n",
    "        \n",
    "        x2 = Conv2D(8, (5, 5), padding='same', activation = 'relu')(x1)\n",
    "        x2 = BatchNormalization()(x2)\n",
    "        x2 = MaxPooling2D(pool_size=(2, 2), padding='same')(x2)\n",
    "        \n",
    "        x3 = Conv2D(16, (5, 5), padding='same', activation = 'relu')(x2)\n",
    "        x3 = BatchNormalization()(x3)\n",
    "        x3 = MaxPooling2D(pool_size=(2, 2), padding='same')(x3)\n",
    "        \n",
    "        x4 = Conv2D(16, (5, 5), padding='same', activation = 'relu')(x3)\n",
    "        x4 = BatchNormalization()(x4)\n",
    "        x4 = MaxPooling2D(pool_size=(4, 4), padding='same')(x4)\n",
    "        \n",
    "        y = Flatten()(x4)\n",
    "        y = Dropout(0.5)(y)\n",
    "        y = Dense(16)(y)\n",
    "        y = LeakyReLU(alpha=0.1)(y)\n",
    "        y = Dropout(0.5)(y)\n",
    "        y = Dense(1, activation = 'sigmoid')(y)\n",
    "\n",
    "        return KerasModel(inputs = x, outputs = y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "7fe25686-10a0-464e-a853-dcc0080828b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MesoInception4(Classifier):\n",
    "    def __init__(self, learning_rate = 0.001):\n",
    "        self.model = self.init_model()\n",
    "        optimizer = Adam(learning_rate = learning_rate)\n",
    "        self.model.compile(optimizer = optimizer, loss = 'mean_squared_error', metrics = ['accuracy'])\n",
    "    \n",
    "    def InceptionLayer(self, a, b, c, d):\n",
    "        def func(x):\n",
    "            x1 = Conv2D(a, (1, 1), padding='same', activation='relu')(x)\n",
    "            \n",
    "            x2 = Conv2D(b, (1, 1), padding='same', activation='relu')(x)\n",
    "            x2 = Conv2D(b, (3, 3), padding='same', activation='relu')(x2)\n",
    "            \n",
    "            x3 = Conv2D(c, (1, 1), padding='same', activation='relu')(x)\n",
    "            x3 = Conv2D(c, (3, 3), dilation_rate = 2, strides = 1, padding='same', activation='relu')(x3)\n",
    "            \n",
    "            x4 = Conv2D(d, (1, 1), padding='same', activation='relu')(x)\n",
    "            x4 = Conv2D(d, (3, 3), dilation_rate = 3, strides = 1, padding='same', activation='relu')(x4)\n",
    "\n",
    "            y = Concatenate(axis = -1)([x1, x2, x3, x4])\n",
    "            \n",
    "            return y\n",
    "        return func\n",
    "    def init_model(self):\n",
    "        x = Input(shape = (IMGWIDTH, IMGWIDTH, 3))\n",
    "        \n",
    "        x1 = self.InceptionLayer(1, 4, 4, 2)(x)\n",
    "        x1 = BatchNormalization()(x1)\n",
    "        x1 = MaxPooling2D(pool_size=(2, 2), padding='same')(x1)\n",
    "        \n",
    "        x2 = self.InceptionLayer(2, 4, 4, 2)(x1)\n",
    "        x2 = BatchNormalization()(x2)\n",
    "        x2 = MaxPooling2D(pool_size=(2, 2), padding='same')(x2)        \n",
    "        \n",
    "        x3 = Conv2D(16, (5, 5), padding='same', activation = 'relu')(x2)\n",
    "        x3 = BatchNormalization()(x3)\n",
    "        x3 = MaxPooling2D(pool_size=(2, 2), padding='same')(x3)\n",
    "        \n",
    "        x4 = Conv2D(16, (5, 5), padding='same', activation = 'relu')(x3)\n",
    "        x4 = BatchNormalization()(x4)\n",
    "        x4 = MaxPooling2D(pool_size=(4, 4), padding='same')(x4)\n",
    "        \n",
    "        y = Flatten()(x4)\n",
    "        y = Dropout(0.5)(y)\n",
    "        y = Dense(16)(y)\n",
    "        y = LeakyReLU(alpha=0.1)(y)\n",
    "        y = Dropout(0.5)(y)\n",
    "        y = Dense(1, activation = 'sigmoid')(y)\n",
    "\n",
    "        return KerasModel(inputs = x, outputs = y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "5c5206f8-588a-498c-ab09-305c167dea02",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Video:\n",
    "    def __init__(self, path):\n",
    "        self.path = path\n",
    "        self.container = imageio.get_reader(path, 'ffmpeg')\n",
    "        self.length = self.container.count_frames()\n",
    "        self.fps = self.container.get_meta_data()['fps']\n",
    "    \n",
    "    def init_head(self):\n",
    "        self.container.set_image_index(0)\n",
    "    \n",
    "    def next_frame(self):\n",
    "        self.container.get_next_data()\n",
    "    \n",
    "    def get(self, key):\n",
    "        return self.container.get_data(key)\n",
    "    \n",
    "    def __call__(self, key):\n",
    "        return self.get(key)\n",
    "    \n",
    "    def __len__(self):\n",
    "        return self.length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "6abb52be-2483-49bf-84af-4d2bb600ee89",
   "metadata": {},
   "outputs": [],
   "source": [
    "class FaceFinder(Video):\n",
    "    def __init__(self, path, load_first_face = True):\n",
    "        super().__init__(path)\n",
    "        self.faces = {}\n",
    "        self.coordinates = {}  \n",
    "        self.last_frame = self.get(0)\n",
    "        self.frame_shape = self.last_frame.shape[:2]\n",
    "        self.last_location = (0, 200, 200, 0)\n",
    "        if (load_first_face):\n",
    "            face_positions = face_recognition.face_locations(self.last_frame, number_of_times_to_upsample=2)\n",
    "            if len(face_positions) > 0:\n",
    "                self.last_location = face_positions[0]\n",
    "    \n",
    "    def load_coordinates(self, filename):\n",
    "        np_coords = np.load(filename)\n",
    "        self.coordinates = np_coords.item()\n",
    "    \n",
    "    def expand_location_zone(self, loc, margin = 0.2):\n",
    "\n",
    "        offset = round(margin * (loc[2] - loc[0]))\n",
    "        y0 = max(loc[0] - offset, 0)\n",
    "        x1 = min(loc[1] + offset, self.frame_shape[1])\n",
    "        y1 = min(loc[2] + offset, self.frame_shape[0])\n",
    "        x0 = max(loc[3] - offset, 0)\n",
    "        return (y0, x1, y1, x0)\n",
    "    \n",
    "    @staticmethod\n",
    "    def upsample_location(reduced_location, upsampled_origin, factor):\n",
    "        y0, x1, y1, x0 = reduced_location\n",
    "        Y0 = round(upsampled_origin[0] + y0 * factor)\n",
    "        X1 = round(upsampled_origin[1] + x1 * factor)\n",
    "        Y1 = round(upsampled_origin[0] + y1 * factor)\n",
    "        X0 = round(upsampled_origin[1] + x0 * factor)\n",
    "        return (Y0, X1, Y1, X0)\n",
    "\n",
    "    @staticmethod\n",
    "    def pop_largest_location(location_list):\n",
    "        max_location = location_list[0]\n",
    "        max_size = 0\n",
    "        if len(location_list) > 1:\n",
    "            for location in location_list:\n",
    "                size = location[2] - location[0]\n",
    "                if size > max_size:\n",
    "                    max_size = size\n",
    "                    max_location = location\n",
    "        return max_location\n",
    "    \n",
    "    @staticmethod\n",
    "    def L2(A, B):\n",
    "        return np.sqrt(np.sum(np.square(A - B)))\n",
    "    \n",
    "    def find_coordinates(self, landmark, K = 2.2):\n",
    "    \n",
    "        E1 = np.mean(landmark['left_eye'], axis=0)\n",
    "        E2 = np.mean(landmark['right_eye'], axis=0)\n",
    "        E = (E1 + E2) / 2\n",
    "        N = np.mean(landmark['nose_tip'], axis=0) / 2 + np.mean(landmark['nose_bridge'], axis=0) / 2\n",
    "        B1 = np.mean(landmark['top_lip'], axis=0)\n",
    "        B2 = np.mean(landmark['bottom_lip'], axis=0)\n",
    "        B = (B1 + B2) / 2\n",
    "\n",
    "        C = N\n",
    "        l1 = self.L2(E1, E2)\n",
    "        l2 = self.L2(B, E)\n",
    "        l = max(l1, l2) * K\n",
    "        if (B[1] == E[1]):\n",
    "            if (B[0] > E[0]):\n",
    "                rot = 90\n",
    "            else:\n",
    "                rot = -90\n",
    "        else:\n",
    "            rot = np.arctan((B[0] - E[0]) / (B[1] - E[1])) / np.pi * 180\n",
    "        \n",
    "        return ((floor(C[1]), floor(C[0])), floor(l), rot)\n",
    "    \n",
    "    \n",
    "    def find_faces(self, resize = 0.5, stop = 0, skipstep = 0, no_face_acceleration_threshold = 3, cut_left = 0, cut_right = -1, use_frameset = False, frameset = []):\n",
    "    \n",
    "        not_found = 0\n",
    "        no_face = 0\n",
    "        no_face_acc = 0\n",
    "        \n",
    "        if (use_frameset):\n",
    "            finder_frameset = frameset\n",
    "        else:\n",
    "            if (stop != 0):\n",
    "                finder_frameset = range(0, min(self.length, stop), skipstep + 1)\n",
    "            else:\n",
    "                finder_frameset = range(0, self.length, skipstep + 1)\n",
    "        \n",
    "        # Quick face finder loop\n",
    "        for i in finder_frameset:\n",
    "            # Get frame\n",
    "            frame = self.get(i)\n",
    "            if (cut_left != 0 or cut_right != -1):\n",
    "                frame[:, :cut_left] = 0\n",
    "                frame[:, cut_right:] = 0            \n",
    "            \n",
    "            # Find face in the previously found zone\n",
    "            potential_location = self.expand_location_zone(self.last_location)\n",
    "            potential_face_patch = frame[potential_location[0]:potential_location[2], potential_location[3]:potential_location[1]]\n",
    "            potential_face_patch_origin = (potential_location[0], potential_location[3])\n",
    "    \n",
    "            reduced_potential_face_patch = zoom(potential_face_patch, (resize, resize, 1))\n",
    "            reduced_face_locations = face_recognition.face_locations(reduced_potential_face_patch, model = 'cnn')\n",
    "            \n",
    "            if len(reduced_face_locations) > 0:\n",
    "                no_face_acc = 0  \n",
    "\n",
    "                reduced_face_location = self.pop_largest_location(reduced_face_locations)\n",
    "                face_location = self.upsample_location(reduced_face_location,\n",
    "                                                    potential_face_patch_origin,\n",
    "                                                    1 / resize)\n",
    "                self.faces[i] = face_location\n",
    "                self.last_location = face_location\n",
    "                \n",
    "                landmarks = face_recognition.face_landmarks(frame, [face_location])\n",
    "                if len(landmarks) > 0:\n",
    "                    self.coordinates[i] = self.find_coordinates(landmarks[0])\n",
    "            else:\n",
    "                not_found += 1\n",
    "\n",
    "                if no_face_acc < no_face_acceleration_threshold:\n",
    "                    face_locations = face_recognition.face_locations(frame, number_of_times_to_upsample = 2)\n",
    "                else:\n",
    "                    reduced_frame = zoom(frame, (resize, resize, 1))\n",
    "                    face_locations = face_recognition.face_locations(reduced_frame)\n",
    "                    \n",
    "                if len(face_locations) > 0:\n",
    "                    print('Face extraction warning : ', i, '- found face in full frame', face_locations)\n",
    "                    no_face_acc = 0  \n",
    "                    \n",
    "                    face_location = self.pop_largest_location(face_locations)\n",
    "                    \n",
    "                    if no_face_acc > no_face_acceleration_threshold:\n",
    "                        face_location = self.upsample_location(face_location, (0, 0), 1 / resize)\n",
    "                    \n",
    "                    self.faces[i] = face_location\n",
    "                    self.last_location = face_location\n",
    "                    \n",
    "                    landmarks = face_recognition.face_landmarks(frame, [face_location])\n",
    "                    if len(landmarks) > 0:\n",
    "                        self.coordinates[i] = self.find_coordinates(landmarks[0])\n",
    "                else:\n",
    "                    print('Face extraction warning : ',i, '- no face')\n",
    "                    no_face_acc += 1\n",
    "                    no_face += 1\n",
    "\n",
    "        print('Face extraction report of', 'not_found :', not_found)\n",
    "        print('Face extraction report of', 'no_face :', no_face)\n",
    "        return 0\n",
    "\n",
    "    def get_face(self, i):\n",
    "        frame = self.get(i)\n",
    "        if i in self.faces:\n",
    "            loc = self.faces[i]\n",
    "            patch = frame[loc[0]:loc[2], loc[3]:loc[1]]\n",
    "            return patch\n",
    "        return frame\n",
    "    \n",
    "    @staticmethod\n",
    "    def get_image_slice(img, y0, y1, x0, x1):\n",
    "        m, n = img.shape[:2]\n",
    "        padding = max(-y0, y1-m, -x0, x1-n, 0)\n",
    "        padded_img = np.pad(img, ((padding, padding), (padding, padding), (0, 0)), 'reflect')\n",
    "        return padded_img[(padding + y0):(padding + y1),\n",
    "                        (padding + x0):(padding + x1)]\n",
    "    \n",
    "    def get_aligned_face(self, i, l_factor = 1.3):\n",
    "        frame = self.get(i)\n",
    "        if i in self.coordinates:\n",
    "            c, l, r = self.coordinates[i]\n",
    "            l = int(l) * l_factor \n",
    "            dl_ = floor(np.sqrt(2) * l / 2) \n",
    "            patch = self.get_image_slice(frame,\n",
    "                                    floor(c[0] - dl_),\n",
    "                                    floor(c[0] + dl_),\n",
    "                                    floor(c[1] - dl_),\n",
    "                                    floor(c[1] + dl_))\n",
    "            rotated_patch = rotate(patch, -r, reshape=False)\n",
    "            return self.get_image_slice(rotated_patch,\n",
    "                                    floor(dl_-l//2),\n",
    "                                    floor(dl_+l//2),\n",
    "                                    floor(dl_-l//2),\n",
    "                                    floor(dl_+l//2))\n",
    "        return frame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "7f11d36f-60af-4fd2-969e-150d4973c638",
   "metadata": {},
   "outputs": [],
   "source": [
    "class FaceBatchGenerator:\n",
    "\n",
    "    def __init__(self, face_finder, target_size = 256):\n",
    "        self.finder = face_finder\n",
    "        self.target_size = target_size\n",
    "        self.head = 0\n",
    "        self.length = int(face_finder.length)\n",
    "\n",
    "    def resize_patch(self, patch):\n",
    "        m, n = patch.shape[:2]\n",
    "        return zoom(patch, (self.target_size / m, self.target_size / n, 1))\n",
    "    \n",
    "    def next_batch(self, batch_size = 50):\n",
    "        batch = np.zeros((1, self.target_size, self.target_size, 3))\n",
    "        stop = min(self.head + batch_size, self.length)\n",
    "        i = 0\n",
    "        while (i < batch_size) and (self.head < self.length):\n",
    "            if self.head in self.finder.coordinates:\n",
    "                patch = self.finder.get_aligned_face(self.head)\n",
    "                batch = np.concatenate((batch, np.expand_dims(self.resize_patch(patch), axis = 0)),\n",
    "                                        axis = 0)\n",
    "                i += 1\n",
    "            self.head += 1\n",
    "        return batch[1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "2bc166ed-e48f-4453-88e8-1e5bcbbaf04b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_faces(generator, classifier, batch_size = 50, output_size = 1):\n",
    "   \n",
    "    n = len(generator.finder.coordinates.items())\n",
    "    profile = np.zeros((1, output_size))\n",
    "    for epoch in range(n // batch_size + 1):\n",
    "        face_batch = generator.next_batch(batch_size = batch_size)\n",
    "        prediction = classifier.predict(face_batch)\n",
    "        if (len(prediction) > 0):\n",
    "            profile = np.concatenate((profile, prediction))\n",
    "    return profile[1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "910d8875-7785-4fcc-b546-3ddfcca337ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_accuracy(classifier, dirname, frame_subsample_count = 30):\n",
    "   \n",
    "    filenames = [f for f in listdir(dirname) if isfile(join(dirname, f)) and ((f[-4:] == '.mp4') or (f[-4:] == '.avi') or (f[-4:] == '.mov'))]\n",
    "    predictions = {}\n",
    "    \n",
    "    for vid in filenames:\n",
    "        print('Dealing with video ', vid)\n",
    "        \n",
    "        face_finder = FaceFinder(join(dirname, vid), load_first_face = False)\n",
    "        skipstep = max(floor(face_finder.length / frame_subsample_count), 0)\n",
    "        face_finder.find_faces(resize=0.5, skipstep = skipstep)\n",
    "        \n",
    "        print('Predicting ', vid)\n",
    "        gen = FaceBatchGenerator(face_finder)\n",
    "        p = predict_faces(gen, classifier)\n",
    "        \n",
    "        predictions[vid[:-4]] = (np.mean(p > 0.5), p)\n",
    "    return predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "0b3be348-95dc-4dd2-9f3b-a69995253413",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "42d59ccc-64a5-4777-93bf-14d026e1291d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "4fe61d93-ed59-472b-adcb-4fb3df6dffee",
   "metadata": {},
   "outputs": [],
   "source": [
    "classifier = Meso4()\n",
    "classifier.load('weights/Meso4_DF.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "7b2b06b5-25e3-4e15-834e-4b096f238fd4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 4 images belonging to 2 classes.\n"
     ]
    }
   ],
   "source": [
    "dataGenerator = ImageDataGenerator(rescale=1./255)\n",
    "generator = dataGenerator.flow_from_directory(\n",
    "        'test_images',\n",
    "        target_size=(256, 256),\n",
    "        batch_size=1,\n",
    "        class_mode='binary',\n",
    "        subset='training')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "eb51b22e-18d6-4402-aae0-486ba20f644f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 68ms/step\n",
      "Predicted : [[0.04532519]] \n",
      "Real class : [0.]\n"
     ]
    }
   ],
   "source": [
    "X, y = generator.next()\n",
    "print('Predicted :', classifier.predict(X), '\\nReal class :', y)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "5c211f29-1584-4556-92fd-22869d761d86",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dealing with video  My Response.mp4\n",
      "Face extraction warning :  0 - found face in full frame [(208, 793, 486, 516)]\n",
      "Face extraction warning :  2208 - found face in full frame [(178, 886, 455, 608)]\n",
      "Face extraction report of not_found : 2\n",
      "Face extraction report of no_face : 0\n",
      "Predicting  My Response.mp4\n",
      "1/1 [==============================] - 0s 116ms/step\n",
      "Dealing with video  This is not Morgan Freeman  -  A Deepfake Singularity.mp4\n",
      "Face extraction warning :  0 - found face in full frame [(173, 789, 405, 558)]\n",
      "Face extraction warning :  1325 - no face\n",
      "Face extraction warning :  1378 - no face\n",
      "Face extraction warning :  1431 - no face\n",
      "Face extraction warning :  1484 - no face\n",
      "Face extraction warning :  1537 - no face\n",
      "Face extraction report of not_found : 6\n",
      "Face extraction report of no_face : 5\n",
      "Predicting  This is not Morgan Freeman  -  A Deepfake Singularity.mp4\n",
      "1/1 [==============================] - 0s 98ms/step\n",
      "`My Response` video class prediction : 1.0\n",
      "`This is not Morgan Freeman  -  A Deepfake Singularity` video class prediction : 1.0\n"
     ]
    }
   ],
   "source": [
    "classifier.load('weights/Meso4_F2F.h5')\n",
    "\n",
    "predictions = compute_accuracy(classifier, 'test_videos')\n",
    "for video_name in predictions:\n",
    "    print('`{}` video class prediction :'.format(video_name), predictions[video_name][0])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
